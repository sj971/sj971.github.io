---
layout: post
title: BRFSS | Population-Level Prediction of Diabetes from Lifestyle and Behavioral Risk Factors
---

## Background

Diabetes is the seventh leading cause of death in the United States and a major public health problem around the world. The [American Diabetes Association](http://main.diabetes.org/dorg/images/infographics/adv-cost-of-diabetes.pdf) estimates the current national cost of diagnosed diabetes at ~$300bn per year, an amount that is likely to rise with increasing diabetes prevalence. 

Data science efforts within health informatics have recently sought to discover risk factors for the disease beyond those standard ones already known (i.e., hypertenstion, cholesterol levels). For example, by studying large-scale medical claims datasets, novel risk factors have recently been found (e.g., co-morbidity with chronic bronchitis, Razavian et al., 2016). Yet, there remains plenty of scope for further exploration of possible risk factors, using more diverse datasets that relate to broader lifestyle factors (i.e., social, economic, or behavioral risk factors).

The Behavioral Risk Factor Surveillance System (BRFSS) is one such dataset: a survey administered annually in the US, with questions touching on the demographic background, health, and behavioral profile of respondents (e.g., healthy eating behaviors, exercise behaviors, etc.). Below, I develop a machine-learning approach to discovering potential risk factors for diabetes from this dataset. I ask the following simple question:

- Can the population-level prediction of diabetes be improved by including broad demographic, health, and behavior-related information in predictive models?

## Exploratory Analysis

For example, a quick exploratory analysis of the BRFSS data illustrates clear asymmetries in the prevalence of diabetes by state (first panel below), with the a substantially higher proportion of the population in South Eastern states suffering from diabetes than in other regions of the US. While there is no established linkage between, for example, healthy eating behaviors and diabetes prevalence, there are potentially broad demographic and lifestyle differences across regions of the country that may play some role in disease prevalence at a population level (e.g., if we assume the distribution of, say, farmer's markets across the US is a proxy for fruit/vegetable consumption, second panel below).

![Exploratory analysis 1]({{ site.baseurl }}/images/figure1_diabetes_prevalence.png "Diabetes prevalence in US")
![Exploratory analysis 2]({{ site.baseurl }}/images/figure1_fmarkets_prevalence.png "Farmer’s markets across US")

## Data Preparation for Model-Fitting

For model-fitting, I focussed on the period from 2011-2015, and specifically data from those odd years (2011, 2013, and 2015) that contained questions related to hypertension and cholesterol. Data for each year (SAS versions) were loaded into RStudio on a local machine and combined. I then focussed on comparing two predictor sets made up of 4 and 16 features respectively:

- Standard model: blood pressure, cholesterol, heart attack, stroke
- Extended model: standard predicto + twelve lifestyle/behavioral predictors (e.g., health rating, alcohol use, fruit/veg consumption)
 
I then set about extracting, recoding, and transforming the variables of interest. I aimed for the clearest possible standardization of variables, binarizing questions where reasonable, and dummy-encoding multi-leveled categorical questions. 

For the healthy-eating variables (e.g., units of fruit or green vegetables consumed/day), a log-transformation did not seem reasonable after initial exploration: even though these were right-ward tailed distributions, a disproportionately large no. of instances of “Never” response were present (i.e., no comsumption of fruit/veg). Thus, I chose to binariz these magnitude variables around a rule-of-thumb threshold to create relatively balanced distributions (e.g., <0.3 units of fruit/day = 0; >0.3 units of fruit/day = 1). 

After transformation and dummy-encoding, all predictor variable columns contained either 0’s and 1’s. For the dependent variable (diabetes diagnosis), I did not include pre-diabetes or ’diabetes during pregnancy only’ respondents. To summarize the variable layout:

	- 10 Binary (balanced): e.g., blood pressure (high/low), cholesterol (high/low), gender, drink/exercise in past 30 days, healthy-eating behaviors (healthy eater/not healthy eater)
	- 2 Binary (assymetric): cardiac infarction, stroke
	- 4 Categorical: general health (Excellent-Poor), Education (8 levels), Income (5 levels), Seatbelt Use (always/ever, 5 levels)
		
Note that the asymmetric binary variables were left as is in the logistic regression models, but that a clustering algorithm explored below accounts for asymmetric binary variables in it’s distance metric. For all variables, missing or don’t know responses were not inputed, but coded as 0 and thus excluded from forming dummy variable column.

## Logistic Regression: Standard and Extended Models

I built a logistic regression model for each of the two question groups (standard/extended). The preprocessed data, which consisted of ~1,500,000 rows x 34 columns after dummy encoding, was first split into training (65%) and test (35%) sets. I then fit each model to the training set, using a 10-fold cross-validation procedure and with L1 regularization as the feature selection approach. L1 regularization penalizes the model log-likelihood by adding the sum of the absolute values of variable coefficients; with an appropriately chosen penalty weight (lambda), this approach forces small beta weights towards zero, aiding in the exploration of the most predictive features in the data. I searched across a set of five lambda values. Models were coded using the ’glmnet’ package in R (which uses bla for optimization):

# code snippet
```R
# prepare the soup
soup = BeautifulSoup(current_listing, 'html.parser')

# find vendor info.
temp = soup.find_all("div", "seller-info text-muted")[0]
vendor = temp.find_all("a")[0].string
```

# split into training/test sets
split <- .65
randInd = runif(nrow(Xy))
train <- Xy[(randInd <= split), ]
test <- Xy[(randInd > split), ]

# prepare variables for logistic regression
k <- 10 #no. cross-validation folds
lseq <- c(.0001, .001, .01, .1, 1, 10) #regularization weights to search through

# fit standard/extended models to training dataset using k-fold cross-validation procedure
smodel <- cv.glmnet(x = train[,1:5], y = train[,35], alpha = 1, lambda = lseq, nfolds = k, 
                         family = 'binomial', type.measure = 'auc')
emodel <- cv.glmnet(x = train[,1:34], y = train[,35], alpha = 1, lambda = lseq, nfolds = k,
                         family = 'binomial', type.measure = 'auc')

To evaluate model performance, I first compared the area under the ROC curve (AUC) for each model (given time constraints, I did not attempt to bootstrap the estimated AUC values to provide a p-value). The additional demographic, health, and behavioral variables appear to improve the overall predictive power of the model, with the extended model (16 variables) having an AUC of 0.81 compared to an AUC of 0.75 for the standard model (4 variables). On examining the coefficient weights, it appears that the categorical question related to general health [with a rating of 1 (excellent) to 5 (poor)] drives this improvement in model performance; beta weights for each of the healthy eating behaviors were close to 0, suggesting little predictive power. Odds ratio: hypertension/health/alco/food. Not surprisingly, standard variables related to hypertension and blood pressure do a good job of predicting diabetes alone. Interestingly, alcohol is negatively related (perhaps reflecting some tendency for avoidance of alcohol among people with diabetes).


## Cluster Analysis

To explore the data using an alternative method, I developed a clustering algorithm that handles the mixed data types found in the BRFSS.
Given the computing constraints of local machine, I loaded the preprocessed data onto an AWS EC2 instance (Linus AMI, m4.2xlarge, 32GB memory)

- most analyses/plots were performed on my local machine using RStudio X2222. For the computationally intensive clustering analysis below (which computes distances for a subset of 20,000 diabetics i.e., 20,000 x 20,000 distance matrix), I uploaded the data (via S3) to an AWS EC2 instance (Linus AMI, m4.2xlarge, 32GB memory). For temporary access….


For example, by sourcing where individual listings were 'Shipped From', we can illustrate the distribution of listings by country of origin. Perhaps not surprisingly, the USA accounts for a large proportion of individual listings (just under 30%), with several European countries also accounting for sizeable portions of the overall market listings (analysis below performed on data from the Evolution website):

## Conclusions

I built on prior attempts to discover novel risk factors for diabetes, extending on approaches that study only medical information to include social and behavioral (i.e., lifestyle) factors. I found novel factors……suggesting lifestyle….. 
- large changes in website formatting across the timeline of the archives
- the lack of detailed drug labeling and categorization at the level of the raw HTML

<!--more-->
