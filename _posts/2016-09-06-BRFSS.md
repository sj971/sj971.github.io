---
layout: post
title: BRFSS | Population-Level Prediction of Diabetes from Lifestyle and Behavioral Risk Factors
---

## Background

Diabetes is the seventh leading cause of death in the United States and a major public health problem around the world. The [American Diabetes Association] (http://main.diabetes.org/dorg/images/infographics/adv-cost-of-diabetes.pdf) estimates the current national cost of diagnosed diabetes at ~$300billion per year, an amount that is likely to rise with increases in diabetes prevalence in recent decades. Data science efforts within health informatics have recently sought to discover risk factors for the disease beyond those standard ones already known (i.e., obesity/hypertenstion/cholesterol levels). For example, by studying large-scale medical claims datasets, novel risk factors have recently been found (e.g., co-morbidity with chronic bronchitis, see Razavian et al., 2016). Yet, there remains plenty of scope for further exploration of possible risk factors, using more diverse datasets that relate to broader lifestyle factors (i.e., social, economic, or behavioral risk factors).

The Behavioral Risk Factor Surveillance System (BRFSS) is one such dataset: a survey administered annually in the US, with questions touching on the demographic background, health, and behavioral profile of respondents (e.g., healthy eating behaviors, exercise behaviors, etc.). Below, I develop a machine-learning approach to discovering potential risk factors for diabetes from this dataset. I ask the following simple question:

- Can the population-level prediction of diabetes be improved by including broader demographic, health, and behavior-related related information as factors in a predictive model of diagnosis?

For example, information on a person’s exercise or healthy eating behavior might is not typically contained in standard health records; Even a courseyet, comparing a map of state-by-state diabetes prevalence to the distribution of farmer’s markets in the US suggests there is at least some rare[farmers market here…]….

![Exploratory analysis 1]({{ site.baseurl }}/images/figure1_diabetes_prevalence.png “Diabetes prevalence in US”)
![Exploratory analysis 2]({{ site.baseurl }}/images/figure1_fmarkets_prevalence.png “Farmer’s markets across US”)

## Data Loading, Transformation, and Exploratory Analysis
I focussed on the period from 2011-2015, and specifically data from those odd years (2011, 2013, and 2015) that contained questions related to hypertension and cholesterol. I combined all of this data, and then focussed on comaring two predictor sets made up of the following features:

- standard model: high blood pressure (Y/N), high cholesterol (Y/N), heart attack (Y/N), stroke (Y/N)
- extended model: standard predictors + twelve demographic/behavioral/healthy eating predictors (e.g., health rating, alcohol/smoking habit, fruit/vegetable consumption)
 
For the main analysis, data (SAS versions) were loaded into RStudio on a local machine. I then set about extracting, recoding and transforming the variables of interest. I aimed for the clearest possible standardization of variables, binarizing questions where it seemed reasonable, and dummy-encoding multi-leveled categorical questions. I utilized the ‘calculated’ healthy eating variables; however, after a simple log-transformation did not seem reasonable for these (even though they were right-ward tailed) due to the large no. of instances of “Never” response. Thus, I binarized these magnitude variables around a rule-of-thumb threshold that created relatively balanced distributions (e.g., <0.3 units of fruit/day = 0; >0.3 units of fruit/day = 1). After transformation/dummy-encoding, all predictor variable columns contained either 0’s and 1’s. For the dependent variable in analyses (DIABETES), I did not include pre-diabetes or ’diabetes during pregnancy only’ respondents. To summarize the variable layout:

	- 10 Binary (balanced): e.g., blood pressure (high/low), cholesterol (high/low), gender, drink/exercise in past 30 days, healthy-eating behaviors (healthy eater/not healthy eater)
	- 2 Binary (assymetric): cardiac infarction, stroke
	- 4 Categorical: general health (Excellent-Poor), Education (8 levels), Income (5 levels), Seatbelt Use (always/ever, 5 levels)
		
Note that the asymmetric binary variables were left as is in the logistic regression models, but that a clustering algorithm explored below accounts for asymmetric binary variables in it’s distance metric. For all variables, missing or don’t know responses were not inputed, but coded as 0 and thus excluded from forming dummy variable column.

## Logistic Regression: Standard and Extended Models

I built a logistic regression model for each of the two question groups (standard/extended). The preprocessed data, which consisted of ~1,500,000 rows x 34 columns after dummy encoding, was first split into training (65%) and test (35%) sets. I then fit each model to the training set, using a 10-fold cross-validation procedure and with L1 regularization as the feature selection approach. L1 regularization penalizes the model log-likelihood by adding the sum of the absolute values of variable coefficients; with an appropriately chosen penalty weight (lambda), this approach forces small beta weights towards zero, aiding in the exploration of the most predictive features in the data. I searched across a set of five lambda values. Models were coded using the ’glmnet’ package in R (which uses bla for optimization):

# code snippet
```R
# prepare the soup
soup = BeautifulSoup(current_listing, 'html.parser')

# find vendor info.
temp = soup.find_all("div", "seller-info text-muted")[0]
vendor = temp.find_all("a")[0].string
```

# split into training/test sets
split <- .65
randInd = runif(nrow(Xy))
train <- Xy[(randInd <= split), ]
test <- Xy[(randInd > split), ]

# prepare variables for logistic regression
k <- 10 #no. cross-validation folds
lseq <- c(.0001, .001, .01, .1, 1, 10) #regularization weights to search through

# fit standard/extended models to training dataset using k-fold cross-validation procedure
smodel <- cv.glmnet(x = train[,1:5], y = train[,35], alpha = 1, lambda = lseq, nfolds = k, 
                         family = 'binomial', type.measure = 'auc')
emodel <- cv.glmnet(x = train[,1:34], y = train[,35], alpha = 1, lambda = lseq, nfolds = k,
                         family = 'binomial', type.measure = 'auc')

To evaluate model performance, I first compared the area under the ROC curve (AUC) for each model (given time constraints, I did not attempt to bootstrap the estimated AUC values to provide a p-value). The additional demographic, health, and behavioral variables appear to improve the overall predictive power of the model, with the extended model (16 variables) having an AUC of 0.81 compared to an AUC of 0.75 for the standard model (4 variables). On examining the coefficient weights, it appears that the categorical question related to general health [with a rating of 1 (excellent) to 5 (poor)] drives this improvement in model performance; beta weights for each of the healthy eating behaviors were close to 0, suggesting little predictive power. Odds ratio: hypertension/health/alco/food. Not surprisingly, standard variables related to hypertension and blood pressure do a good job of predicting diabetes alone. Interestingly, alcohol is negatively related (perhaps reflecting some tendency for avoidance of alcohol among people with diabetes).


## Cluster Analysis

To explore the data using an alternative method, I developed a clustering algorithm that handles the mixed data types found in the BRFSS.
Given the computing constraints of local machine, I loaded the preprocessed data onto an AWS EC2 instance (Linus AMI, m4.2xlarge, 32GB memory)

- most analyses/plots were performed on my local machine using RStudio X2222. For the computationally intensive clustering analysis below (which computes distances for a subset of 20,000 diabetics i.e., 20,000 x 20,000 distance matrix), I uploaded the data (via S3) to an AWS EC2 instance (Linus AMI, m4.2xlarge, 32GB memory). For temporary access….


For example, by sourcing where individual listings were 'Shipped From', we can illustrate the distribution of listings by country of origin. Perhaps not surprisingly, the USA accounts for a large proportion of individual listings (just under 30%), with several European countries also accounting for sizeable portions of the overall market listings (analysis below performed on data from the Evolution website):

## Conclusions

I built on prior attempts to discover novel risk factors for diabetes, extending on approaches that study only medical information to include social and behavioral (i.e., lifestyle) factors. I found novel factors……suggesting lifestyle….. 
- large changes in website formatting across the timeline of the archives
- the lack of detailed drug labeling and categorization at the level of the raw HTML

<!--more-->
